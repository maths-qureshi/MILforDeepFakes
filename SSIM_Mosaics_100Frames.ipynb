{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multiple Instance Learning (MIL) for DeepFake Detections"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This project was conceived in a conversation with Chris Farnan at PaigeAI. The idea was to use MIL for detecting DeepFakes using the technique used successfully by PaigeAI to find tumorous slides in thousands of samples available to them. This script was used to prepare data to use with the training script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing the required modules\n",
    "\n",
    "import os\n",
    "import cv2\n",
    "import json\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage.measure import compare_ssim\n",
    "import imutils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "#setting the seed for reproducible train/test data splitting\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#More than 475GB of data was available with the metadata in 10 json files. \n",
    "#We were only able to use a subset as there was not enough space available on the hard drive to store all the data\n",
    "json_filenames=['../train_sample_videos/metadata.json','../train_sample_videos/metadata_prt2.json']\n",
    "#json_filenames=['../train_sample_videos/metadata.json','../train_sample_videos/metadata_prt2.json','../train_sample_videos/metadata_prt3.json']\n",
    "train_dir='../train_sample_videos/'\n",
    "lstSlides=[]\n",
    "lstTargets=[]\n",
    "\n",
    "#extracting the names of all the Fake files with the counterpart Real (i.e. Unfake) file available\n",
    "for json_filename in json_filenames:\n",
    "    with open(json_filename) as json_file:\n",
    "        data=json.load(json_file)\n",
    "        for item in data:\n",
    "            Filename=item     \n",
    "            Label=data[item]['label']\n",
    "\n",
    "\n",
    "            if Label=='FAKE':\n",
    "                fake_filename_path=train_dir+Filename\n",
    "                real_filename=data[item]['original']\n",
    "                real_filename_path=train_dir+real_filename\n",
    "\n",
    "                if os.path.exists(real_filename_path):\n",
    "                    lstSlides.append(Filename)\n",
    "                    lstTargets.append(1)\n",
    "            else:\n",
    "                if Filename not in lstSlides:\n",
    "                    lstSlides.append(Filename)\n",
    "                    lstTargets.append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#using scikit learn to split the test train data-set with 90% for training and 10% for testing\n",
    "lstSlides_train, lstSlides_test, lstTargets_train, lstTargets_test = train_test_split(lstSlides, lstTargets, test_size=0.1, random_state=42, stratify=lstTargets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Number of files in the train data-set\n",
    "lstTargets_train.count(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Number of files in test data-set\n",
    "lstTargets_test.count(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to find fake area inside two frames when provided with the real and fake image frame\n",
    "def fn_find_fake_area(img_real, img_fake, nDisplayNum==0):\n",
    "    if (img_real.shape!=img_fake.shape):\n",
    "        print(\"ERROR: Img dimensions do not match...\")\n",
    "        return (None, None)\n",
    "    mask=np.zeros(img_real.shape)\n",
    "    (score, diff)=compare_ssim(img_real,img_fake,full=True)\n",
    "    #print(np.min(diff))\n",
    "    mask[diff<0.8]=255\n",
    "    \n",
    "    #Display some intermediate results\n",
    "    if nDisplayNum>0:\n",
    "        plt.figure()\n",
    "        plt.imshow(img_real, cmap='gray')\n",
    "        plt.figure()\n",
    "        plt.imshow(img_fake, cmap='gray')\n",
    "        plt.figure()\n",
    "        plt.imshow(diff, cmap='gray')\n",
    "        plt.figure()\n",
    "        plt.imshow(mask, cmap='gray')\n",
    "    \n",
    "    #Find contours with fake area\n",
    "    cnts = cv2.findContours(mask.astype(\"uint8\"), cv2.RETR_EXTERNAL,cv2.CHAIN_APPROX_SIMPLE)\n",
    "    cnts = imutils.grab_contours(cnts)\n",
    "    if len(cnts)==0:\n",
    "        return (None, None)\n",
    "    c = max(cnts, key=cv2.contourArea)\n",
    "    (x, y, w, h) = cv2.boundingRect(c)\n",
    "    return (x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to write the PIL image\n",
    "def write_image(filename,frame):\n",
    "    #comp_filename=dirname+'/'+filename\n",
    "    frame.save(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import torch\n",
    "\n",
    "#Idea is to create a Mosaic out of the entire video with a certain number of frames from real and fake videos\n",
    "#The data is processed to approximate the requirements of the PaigeAI MIL code and simulate a pathology slide\n",
    "#I have ensured as many samples of real and fake are included in each image as possible simulating a Tumor slide\n",
    "Frames_per_row=5*2 #these many frames will be in a row\n",
    "Max_Frame=50*2 #50 frames will be acquired from real and 50 from fake, the number is low because of the lack of space\n",
    "\n",
    "\n",
    "mpg_inputdir='../train_sample_videos/'\n",
    "#mpg_inputdir='../difficult_videos/'\n",
    "#This function processed the videos to create a Mosaic\n",
    "def process_video_mosaic_ssim(json_filename_lst,lstFiles,output_dir=None):\n",
    "    nFileCnt=0\n",
    "    lstSlides=[]\n",
    "    lstGrid=[]\n",
    "    lstTargets=[]\n",
    "    lstMult=[]\n",
    "    lstLevel=[]\n",
    "    bDispFlg=False\n",
    "    \n",
    "    if output_dir==None:\n",
    "        output_dir='MosaicFiles_Strat_RandSeed42_'+str(Max_Frame)+'/'\n",
    "    \n",
    "    if not os.path.exists(output_dir):\n",
    "        os.mkdir(output_dir)\n",
    "        \n",
    "    sizeC=int(Frames_per_row*224)\n",
    "    sizeR=int((Max_Frame/Frames_per_row)*224)\n",
    "    #print(\"Size Mosaic:\",sizeR,sizeC)\n",
    "    mosaic_frm=Image.new('RGB',(sizeC,sizeR))\n",
    "    lstProcFilenames=[]\n",
    "    \n",
    "    #processing the files listed in the json files, can be skipped if the filenames are stored in the first instance\n",
    "    for json_filename in json_filename_lst:\n",
    "        with open(json_filename) as json_file:\n",
    "            data=json.load(json_file)\n",
    "            for item in data:\n",
    "                Filename=item\n",
    "                print('===================================================')\n",
    "                print(Filename,'->',data[item])\n",
    "\n",
    "                #Processing testing and training separately for only the files selected earlier\n",
    "                if Filename not in lstFiles:\n",
    "                    print(\"Skipping as not in list...\")\n",
    "                    continue\n",
    "                dirname=Filename[:-4]\n",
    "                print(\"Processing:\",item,data[item])\n",
    "                Label=data[item]['label']\n",
    "                \n",
    "                strOutFilename=output_dir+dirname+'.png'\n",
    "                \n",
    "                #if os.path.exists(strOutFilename):\n",
    "                #    continue\n",
    "                #lstSlides.append(Filename)\n",
    "                \n",
    "                if Label=='FAKE':\n",
    "                    fake_filename_path=train_dir+Filename\n",
    "                    orig_filename=data[item]['original']\n",
    "                    real_filename_path=train_dir+orig_filename\n",
    "\n",
    "                    if os.path.exists(real_filename_path):\n",
    "                        real_mpg_File=cv2.VideoCapture(real_filename_path)\n",
    "                        fake_mpg_File=cv2.VideoCapture(fake_filename_path)\n",
    "\n",
    "                        lstIndices=[]\n",
    "                        nFrameCnt=0\n",
    "                        nRowCnt=0\n",
    "                        bFirstFrame=False\n",
    "                        \n",
    "                        #Processing each frame in the video file\n",
    "                        while(fake_mpg_File.isOpened() and real_mpg_File.isOpened()):\n",
    "                            ret_real, frame_real=real_mpg_File.read()\n",
    "                            ret_fake, frame_fake=fake_mpg_File.read()\n",
    "                            frame_real=cv2.cvtColor(frame_real, cv2.COLOR_BGR2RGB)\n",
    "                            frame_fake=cv2.cvtColor(frame_fake, cv2.COLOR_BGR2RGB)\n",
    "                            (nR,nC,nD)=frame_real.shape\n",
    "                            #print(\"Dimensions:\",nR,nC,nD)\n",
    "\n",
    "                            if ret_real==True and ret_fake==True:\n",
    "                                frame_real_grey=cv2.cvtColor(frame_real, cv2.COLOR_BGR2GRAY)\n",
    "                                frame_fake_grey=cv2.cvtColor(frame_fake, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "                                #(score, diff)=compare_ssim(frame_real_grey,frame_fake_grey,full=True)\n",
    "                                #print(score)\n",
    "                                (ptx_fk,pty_fk)=fn_find_fake_area(frame_real_grey,frame_fake_grey)\n",
    "                                #(ptx_rl,pty_rl)=fn_find_non_fake_area(frame_real_grey,frame_fake_grey)\n",
    "\n",
    "                                print(\"Fake pts:\",ptx_fk,pty_fk)\n",
    "                                #print(\"Real pts:\",ptx_rl,pty_rl)\n",
    "\n",
    "                                if ptx_fk!=None and pty_fk!=None:\n",
    "                                    #Placing rectangle for visualization of real and fake areas\n",
    "                                    #cv2.rectangle(frame_real, (ptx_fk, pty_fk), (ptx_fk + 224, pty_fk + 224), (255, 255, 255), 2)\n",
    "                                    #cv2.rectangle(frame_fake, (ptx_fk, pty_fk), (ptx_fk + 224, pty_fk + 224), (255, 255, 255), 2)\n",
    "\n",
    "                                    #cv2.rectangle(frame_real, (ptx_rl, pty_rl), (ptx_rl + 224, pty_rl + 224), (0, 255, 0), 2)\n",
    "                                    #cv2.rectangle(frame_fake, (ptx_rl, pty_rl), (ptx_rl + 224, pty_rl + 224), (0, 255, 0), 2)\n",
    "                                    \n",
    "                                    pty_strt=pty_fk-112\n",
    "                                    pty_end=pty_fk+112\n",
    "                                    ptx_strt=ptx_fk-112\n",
    "                                    ptx_end=ptx_fk+112\n",
    "                                    \n",
    "                                    #Resolving the situation when the ROI occurs at the edge with not enough\n",
    "                                    #pixels to acquire a map of 224X224\n",
    "                                    if pty_strt<0:\n",
    "                                        pty_strt=0\n",
    "                                        pty_end=pty_strt+224\n",
    "                                    elif pty_end>nR:\n",
    "                                        pty_strt=nR-224\n",
    "                                        pty_end=nR\n",
    "\n",
    "                                    if ptx_strt<0:\n",
    "                                        ptx_strt=0\n",
    "                                        ptx_end=ptx_strt+224\n",
    "                                    elif ptx_end>nC:\n",
    "                                        ptx_strt=nC-224\n",
    "                                        ptx_end=nC\n",
    "\n",
    "                                    print(\"Fake pts:\",ptx_strt,ptx_end,pty_strt,pty_end)\n",
    "                                    #print(\"Real pts:\",ptx_rl_strt,ptx_rl_end,pty_rl_strt,pty_rl_end)\n",
    "                                    area_real=frame_real[pty_strt:pty_end,ptx_strt:ptx_end]\n",
    "                                    area_fake=frame_fake[pty_strt:pty_end,ptx_strt:ptx_end]\n",
    "\n",
    "                                    im_pil_rl = Image.fromarray(area_real)\n",
    "                                    im_pil_fk = Image.fromarray(area_fake)\n",
    "                                    \n",
    "                                    #Acquiring indexes inside the mosaic to place extracted RoIs in\n",
    "                                    nXIndex=(nFrameCnt%Frames_per_row)*224\n",
    "                                    nYIndex=nRowCnt*224\n",
    "                                    print(nXIndex,nYIndex)\n",
    "                                    #Placing the real image in the mosaic\n",
    "                                    mosaic_frm.paste(im_pil_rl,(nXIndex,nYIndex))\n",
    "                                    lstIndices.append((nXIndex, nYIndex))\n",
    "                                    nFrameCnt=nFrameCnt+1\n",
    "                                    #Placing the fake image in the mosaic\n",
    "                                    nXIndex=(nFrameCnt%Frames_per_row)*224\n",
    "                                    nYIndex=nRowCnt*224\n",
    "                                    mosaic_frm.paste(im_pil_fk,(nXIndex,nYIndex))\n",
    "                                    lstIndices.append((nXIndex, nYIndex))\n",
    "                                    nFrameCnt=nFrameCnt+1\n",
    "\n",
    "                                    if nFrameCnt%Frames_per_row==0:\n",
    "                                        nRowCnt=nRowCnt+1\n",
    "\n",
    "                                    if bDispFlg:\n",
    "                                        plt.figure()\n",
    "                                        plt.imshow(im_pil_rl)\n",
    "\n",
    "                                    lstTargets.append(0)\n",
    "                                    lstTargets.append(1)\n",
    "                                    if nFrameCnt<Max_Frame: #Process only upto a maximum of frames defined\n",
    "                                        print(\"****Frame:\",nFrameCnt)\n",
    "                                    else:\n",
    "                                        print(\"Writing file:\",strOutFilename)\n",
    "                                        write_image(strOutFilename,mosaic_frm)\n",
    "                                        lstSlides.append(strOutFilename)\n",
    "                                        lstGrid.append(lstIndices)\n",
    "                                        break\n",
    "                            else:\n",
    "                                break\n",
    "\n",
    "\n",
    "                lstMult.append(0)\n",
    "                lstLevel.append(1)\n",
    "\n",
    "                nFileCnt=nFileCnt+1\n",
    "                \n",
    "                resDict= {\n",
    "                    \"slides\": lstSlides,\n",
    "                    \"grid\": lstGrid,\n",
    "                    \"targets\": lstTargets,\n",
    "                    \"mult\": lstMult,\n",
    "                    \"level\": lstLevel\n",
    "                }\n",
    "                torch.save(resDict,\"MIL_data_dict_train_intermed\")\n",
    "                \n",
    "                \n",
    "    \n",
    "    print(lstSlides)\n",
    "    print(lstGrid)\n",
    "    print(lstTargets)\n",
    "    \n",
    "    #lstSlides_train, lstSlides_test, y_train, y_test = train_test_split(lstSlides, lstGrid, lstMult, lstLevel, lstTargets, test_size=0.1, random_state=42, stratify=lstTargets)\n",
    "    \n",
    "    resDict= {\n",
    "        \"slides\": lstSlides,\n",
    "        \"grid\": lstGrid,\n",
    "        \"targets\": lstTargets,\n",
    "        \"mult\": lstMult,\n",
    "        \"level\": lstLevel\n",
    "    }  \n",
    "    \n",
    "    return resDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#processing the training data to acquire MIL dictionary\n",
    "dictMILTrain=process_video_mosaic_ssim(json_filenames, lstSlides_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(dictMILTrain,\"MIL_data_dict_train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#processing the test data to acquire MIL dictionary \n",
    "dictMILTest=process_video_mosaic_ssim(json_filenames, lstSlides_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(dictMILTest,\"MIL_data_dict_test\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
