{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multiple Instance Learning (MIL) for DeepFake Detections"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This project was conceived in a conversation with Chris Farnan at PaigeAI. The idea was to use MIL for detecting DeepFakes using the technique used successfully by PaigeAI to find tumorous slides in thousands of samples available to them. This script was used to prepare data to use with the training script."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#More than 475GB of data was available with the metadata in 10 json files. \n",
    "#We were only able to use a subset as there was not enough space available on the hard drive to store all the data\n",
    "json_filenames=['../train_sample_videos/metadata.json','../train_sample_videos/metadata_prt2.json','../train_sample_videos/metadata_prt3.json']\n",
    "lstSlides=[]\n",
    "lstTargets=[]\n",
    "for json_filename in json_filenames:\n",
    "    with open(json_filename) as json_file:\n",
    "        data=json.load(json_file)\n",
    "        for item in data:\n",
    "            Filename=item     \n",
    "            Label=data[item]['label']\n",
    "\n",
    "            lstSlides.append(Filename)\n",
    "\n",
    "            if Label=='FAKE':\n",
    "                lstTargets.append(1)\n",
    "            else:\n",
    "                lstTargets.append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#using scikit learn to split the test train data-set with 90% for training and 10% for testing\n",
    "lstSlides_train, lstSlides_test, lstTargets_train, lstTargets_test = train_test_split(lstSlides, lstTargets, test_size=0.1, random_state=42, stratify=lstTargets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Number of files in train data-set\n",
    "lstTargets_train.count(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "\n",
    "from yolo.yolo import YOLO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Args:\n",
    "    model='model-weights/YOLO_Face.h5'\n",
    "    anchors='cfg/yolo_anchors.txt'\n",
    "    classes='cfg/face_classes.txt'\n",
    "    score=0.5\n",
    "    iou=0.45\n",
    "    img_size=(416, 416)\n",
    "    image=False\n",
    "    video='samples/abofeumbvv.mp4' #'samples/acqfdwsrhi.mp4'\n",
    "    output='outputs/'\n",
    "\n",
    "# Get the arguments\n",
    "args=Args()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import colorsys\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from yolo.model import eval\n",
    "\n",
    "from keras import backend as K\n",
    "from keras.models import load_model\n",
    "from timeit import default_timer as timer\n",
    "from PIL import ImageDraw, Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_image(filename,frame):\n",
    "    #comp_filename=dirname+'/'+filename\n",
    "    frame.save(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "Frames_per_row=10\n",
    "Max_Frame=100\n",
    "\n",
    "\n",
    "#if not os.path.exists(output_dir):\n",
    "#    os.mkdir(output_dir)\n",
    "mpg_inputdir='../train_sample_videos/'\n",
    "#mpg_inputdir='../difficult_videos/'\n",
    "#This function processed the videos to create a Mosaic. It uses YOLO to detect a Face and then places it in a Mosaic. \n",
    "#Each video will create a Mosaic of multiple faces detected in the video.\n",
    "def process_video_mosaic(model,json_filename,lstFiles,output_dir=None):\n",
    "    nFileCnt=0\n",
    "    lstSlides=[]\n",
    "    lstGrid=[]\n",
    "    lstTargets=[]\n",
    "    lstMult=[]\n",
    "    lstLevel=[]\n",
    "    bDispFlg=False\n",
    "    \n",
    "    if output_dir==None:\n",
    "        output_dir='MosaicFiles_Strat'+str(Max_Frame)+'/'\n",
    "    \n",
    "    if not os.path.exists(output_dir):\n",
    "        os.mkdir(output_dir)\n",
    "        \n",
    "    with open(json_filename) as json_file:\n",
    "        data=json.load(json_file)\n",
    "        for item in data:\n",
    "            Filename=item\n",
    "            print('===================================================')\n",
    "            print(Filename,'->',data[item])\n",
    "            #Processing testing and training separately\n",
    "            if Filename not in lstFiles:\n",
    "                print(\"Skipping as not in list...\")\n",
    "                continue\n",
    "            #print('Label: ',data[item]['label'])\n",
    "            Label=data[item]['label']\n",
    "    \n",
    "            dirname=Filename[:-4]\n",
    "            output_dir_cur=output_dir\n",
    "            file_path=mpg_inputdir+Filename\n",
    "            \n",
    "            mpg_File=cv2.VideoCapture(file_path)\n",
    "            if (mpg_File.isOpened()==False):\n",
    "                print('Error: reading the input file: ',Filename)\n",
    "            video_size = (int(mpg_File.get(cv2.CAP_PROP_FRAME_WIDTH)),\n",
    "            int(mpg_File.get(cv2.CAP_PROP_FRAME_HEIGHT)))\n",
    "            \n",
    "            lstIndices=[]\n",
    "            nFrameCnt=0\n",
    "            nRowCnt=0\n",
    "            bFirstFrame=False\n",
    "            sizeC=int(Frames_per_row*224)\n",
    "            sizeR=int((Max_Frame/Frames_per_row)*224)\n",
    "            #print(\"Size Mosaic:\",sizeR,sizeC)\n",
    "            mosaic_frm=Image.new('RGB',(sizeC,sizeR))\n",
    "            \n",
    "            print(\"Reading file...\")\n",
    "            while(mpg_File.isOpened()):\n",
    "                ret, frame=mpg_File.read()\n",
    "\n",
    "                if (ret==True):\n",
    "                    #print(\"Frame read...\")\n",
    "                    #cv2.imshow('Frame',frame)\n",
    "                    #print(frame.shape)\n",
    "                    frame=cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "                    image = Image.fromarray(frame)\n",
    "                    np_image = np.asarray(image)\n",
    "                    image_rec, faces = model.detect_image(image)\n",
    "                    result = np.asarray(image_rec)\n",
    "                    print(\"Face:\",faces)\n",
    "\n",
    "                    for face in faces:\n",
    "                        x1=int(np.round(face[0]))\n",
    "                        y1=int(np.round(face[1]))\n",
    "                        x2=int(np.round(face[2]))\n",
    "                        y2=int(np.round(face[3]))\n",
    "\n",
    "                        w=x2-x1\n",
    "                        h=y2-y1\n",
    "                        border_x=int((224-w)/2)\n",
    "                        border_y=int((224-h)/2)\n",
    "                        if (x1-border_x)<0:\n",
    "                            x1=0\n",
    "                            x2=x1+224\n",
    "                        else:\n",
    "                            x1=x1-border_x\n",
    "                        if (x2+border_x)>video_size[1]:  #width and height order are reversed in the face structure, fix it later\n",
    "                            x2=video_size[1]\n",
    "                            x1=x2-224\n",
    "                        else:\n",
    "                            x2=x2+border_x\n",
    "                        if (y1-border_y)<0:\n",
    "                            y1=0\n",
    "                            y2=y1+224\n",
    "                        else:\n",
    "                            y1=y1-border_y\n",
    "                        if (y2+border_y)>video_size[0]:\n",
    "                            y2=video_size[0]\n",
    "                            y1=y2-224\n",
    "                        else:\n",
    "                            y2=y2+border_y\n",
    "                        print(\"Face info:\",x1,y1,x2,y2,w,h)\n",
    "\n",
    "                        face_frame=np_image[x1:x2,y1:y2,:] #face is equivalent to the required frames here\n",
    "                        im_pil = Image.fromarray(face_frame)\n",
    "                        nXIndex=(nFrameCnt%Frames_per_row)*224\n",
    "                        nYIndex=nRowCnt*224\n",
    "                        mosaic_frm.paste(im_pil,(nXIndex,nYIndex))\n",
    "                        lstIndices.append((nXIndex, nYIndex))\n",
    "                        nFrameCnt=nFrameCnt+1\n",
    "                        if nFrameCnt>=Max_Frame:\n",
    "                            print(\"WARNING: FRAME COUNT BREACHED...\")\n",
    "                            break\n",
    "                        if nFrameCnt%Frames_per_row==0:\n",
    "                            nRowCnt=nRowCnt+1\n",
    "                            \n",
    "                        if bDispFlg:\n",
    "                            plt.figure()\n",
    "                            plt.imshow(face_frame)\n",
    "                    \n",
    "                    if nFrameCnt<Max_Frame:\n",
    "                        print(\"****Frame:\",nFrameCnt)\n",
    "\n",
    "                    else:\n",
    "                        #plt.figure()\n",
    "                        #plt.imshow(mosaic_frm)\n",
    "                        strFilename=output_dir_cur+dirname+'.png'\n",
    "                        #if not os.path.exists(strFilename):\n",
    "                        write_image(strFilename,mosaic_frm)\n",
    "                        lstSlides.append(strFilename)\n",
    "                        lstGrid.append(lstIndices)\n",
    "                        break\n",
    "                else:\n",
    "                    break\n",
    "                    \n",
    "            if Label=='FAKE':\n",
    "                lstTargets.append(1)\n",
    "            else:\n",
    "                lstTargets.append(0)\n",
    "            lstMult.append(1)\n",
    "            lstLevel.append(0)\n",
    "                \n",
    "            nFileCnt=nFileCnt+1\n",
    "            #f (nFileCnt>2):\n",
    "             #  break\n",
    "    \n",
    "    print(lstSlides)\n",
    "    print(lstGrid)\n",
    "    print(lstTargets)\n",
    "    \n",
    "    #lstSlides_train, lstSlides_test, y_train, y_test = train_test_split(lstSlides, lstGrid, lstMult, lstLevel, lstTargets, test_size=0.1, random_state=42, stratify=lstTargets)\n",
    "    \n",
    "    resDict= {\n",
    "        \"slides\": lstSlides,\n",
    "        \"grid\": lstGrid,\n",
    "        \"targets\": lstTargets,\n",
    "        \"mult\": lstMult,\n",
    "        \"level\": lstLevel\n",
    "    }  #dict(zip(lstSlides,lstGrid,lstTargets,lstMult,lstLevel))\n",
    "    \n",
    "    return resDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=YOLO(args)\n",
    "dictMILTrain=process_video_mosaic(model,json_filename, lstSlides_train)\n",
    "#model.close_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "json.dump(dictMILTrain,open('MIL_data_dict_train.json','w'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictMILTest=process_video_mosaic(model,json_filename, lstSlides_test)\n",
    "model.close_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "json.dump(dictMILTest,open('MIL_data_dict_test.json','w'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
